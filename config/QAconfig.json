{
  "train": {
    "batch_size": 32,
    "weight_decay": 0.0,
    "lr": 1e-3,
    "lr_decay": 0.9,
    "warm_up_proportion": 0,
    "epoch": 50
  },
  "encoder": {
    "embedding_size": 128,
    "hidden_size": 384,
    "hidden_layer": 1,
    "attention_head": 12,
    "intermediate_size": 1536,
    "max_sequence_length": 512,
    "vocab_size": 32000,
    "layer_norm_eps": 1e-12,
    "output_all_hidden": false,
    "share_type": "shared_attention"
  },
  "decoder": {
    "num_label": 2
  }
}